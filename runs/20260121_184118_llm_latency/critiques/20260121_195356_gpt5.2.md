# GPT-5.2 Critique Log

Model: gpt-5.2
Reasoning effort: high

## Critique of structure and flow
- Flow starts midstream: no quick “why latency matters” + “how we measure it” framing for TTFT/TBT and p50/p99.
- Mixed units/metrics (time between tokens vs tokens/min/GPU); pick one rate and one time consistently.
- Slides don’t consistently tag whether they affect TTFT vs TBT and compute/memory/queue.
- Congestion/batching/routing overlap; should form a clear queueing + scheduling chapter.
- Input vs output and cached prefix lack the shared cost model (KV cache growth + per-step decode).
- Long requests should follow a dedicated context/KV cache explanation.
- Speedups list lacks a decision framework mapping levers to symptoms.

## Missing or weak content
- End-to-end latency budget (client → gateway → queue → prefill → decode → postprocess).
- Metrics slide defining TTFT, tok/s or ms/token, and p50/p99.
- “What dominates when” slide (small prompts vs long contexts vs long generations).
- Clear explanation of why output dominates: sequential decode + KV cache growth; often memory-bandwidth bound.
- Bottleneck taxonomy slide (Compute / Memory / Queue / Network).
- Closing playbook mapping levers to TTFT vs TBT vs p99 spikes.
- Optional baseline numbers (orders of magnitude) for intuition.

## Motif system
- Primary metaphor: Token traffic on a two-stage expressway (prefill on-ramp, decode cruise, queues as toll plazas, KV cache as growing trailer).
- Palette: Prefill/TTFT blue (#2563EB), Decode/TBT teal (#14B8A6), Queue amber (#F59E0B), Slate neutrals (#0F172A/#64748B) on light gray (#F8FAFC).
- Icon set: clock, chip, memory stack, cars/lanes, queue/toll gate, routing arrows, scale triangle, lightning/gear, server rack, accelerator card.
- Layout system: 12-column grid; 70/30 split (hero visual + 1-3 short callouts); fixed header band with TTFT/tok/s/p99 tags.
- Recurring elements:
  - Token pills flowing left→right (blue prefill, teal decode)
  - Thin “latency ruler” with short labels (ms, tok/s, p99)
  - Bottleneck badges: Compute / Memory / Queue / Network
  - Mini-legend for TTFT vs Decode cadence
  - Very short axis labels

## Refined slide list (proposed)
1. 00_cover — LLM Latency: premise and context for TTFT + cadence.
2. 01_what_makes_slow — Section opener: where time goes and why it spikes.
3. 02_latency_metrics — Metrics: TTFT, tok/s, p50/p99.
4. 03_latency_budget — End-to-end pipeline: client→gateway→queue→prefill→decode→postprocess.
5. 04_tradeoffs — Capability × Cost × Latency triangle.
6. 05_latency_components — Prefill vs decode phases.
7. 06_model_size — Size increases per-token work and memory traffic.
8. 07_output_dominates — Generation is sequential; outputs add linearly.
9. 08_context_length_kv_growth — Longer context increases KV cache footprint; memory-bound.
10. 09_cached_prefix — Reuse cuts prefill/TTFT for repeated prompts.
11. 10_batch_size_tradeoff — Throughput vs per-request waiting.
12. 11_highway_congestion — Queueing near saturation spikes p99.
13. 12_global_routing_vs_queue — Route farther vs wait locally.
14. 13_long_requests_cost — Long contexts/outputs break batching fairness; tails.
15. 14_speedups — Section opener for levers.
16. 15_smaller_models — Distillation/compact models improve tok/s and TTFT.
17. 16_moe_sparsity — Activate fewer experts per token.
18. 17_proxy_models — Draft-and-verify reduces sequential steps.
19. 18_quantization — Lower precision boosts throughput, quality risk.
20. 19_kv_cache — Reuse/paging/eviction/compression for stable tok/s.
21. 20_add_capacity — Scale replicas; reduce queueing and p99.
22. 21_new_hardware — Faster accelerators improve compute + memory bandwidth.
23. 22_playbook — Decision map: choose levers by symptom.
